# MLOps Pipeline Demo Script (Under 5 Minutes)

## üé¨ Video Recording Script

### üìã Equipment Setup
- Screen recording software ready
- Terminal/PowerShell window visible
- Browser window ready for dashboards
- Project directory: `C:\Users\vidhi\Downloads\MLOPS Assignment 2`

---

## üé• SCENE 1: Introduction (30 seconds)

**What to Say:**
"Hi! Today I'll demonstrate a complete MLOps pipeline for a Cats vs Dogs classification model. This pipeline includes model training, containerization, deployment, monitoring, and CI/CD automation. Let's start by exploring the project structure."

**Actions:**
- Show project directory structure
- Highlight key folders: `src/`, `models/`, `k8s/`, `.github/`, `monitoring/`

---

## üé• SCENE 2: Code Change & Git Integration (45 seconds)

**What to Say:**
"Let's make a small change to our model configuration to demonstrate the CI/CD pipeline. We'll increase the learning rate slightly and commit this change."

**Commands to Run:**
```powershell
# Show current config
cat config.json

# Make a small change
(Get-Content config.json) -replace '"learning_rate": 0.0001', '"learning_rate": 0.0002' | Set-Content config.json

# Show the change
cat config.json

# Git commit the change
git add config.json
git commit -m "Update learning rate to 0.0002 for better convergence"
git status
```

**What to Explain:**
- "This change will trigger our GitHub Actions CI/CD pipeline"
- "The pipeline will automatically test, build, and deploy our model"

---

## üé• SCENE 3: Local Deployment (60 seconds)

**What to Say:**
"Now let's deploy our MLOps pipeline locally using Docker Compose. This will spin up our inference service, monitoring stack, and MLflow tracking."

**Commands to Run:**
```powershell
# Stop any existing services
docker-compose down

# Deploy the complete stack
docker-compose up -d --build

# Wait for services to start
sleep 30

# Check service status
docker-compose ps
```

**What to Explain:**
- "Docker Compose orchestrates 4 services: inference, Prometheus, Grafana, MLflow"
- "Each service is containerized and connected"
- "Health checks ensure services are ready"

---

## üé• SCENE 4: Smoke Testing (45 seconds)

**What to Say:**
"Let's run our comprehensive smoke tests to verify all services are working correctly."

**Commands to Run:**
```powershell
# Run smoke tests
python smoke_tests.py

# Show test results
```

**What to Explain:**
- "Smoke tests verify health checks, predictions, metrics, and monitoring"
- "All 6 services should pass: API, Grafana, Prometheus, MLflow"
- "This ensures our deployment is production-ready"

---

## üé• SCENE 5: Model Prediction Demo (45 seconds)

**What to Say:**
"Now let's test our deployed model with both cat and dog images to see the predictions."

**Commands to Run:**
```powershell
# Test with cat image
curl.exe -X POST -F "file=@Test_img.jpg" http://localhost:8000/predict

# Test with dog image  
curl.exe -X POST -F "file=@Test_img1.jpg" http://localhost:8000/predict
```

**What to Explain:**
- "The API returns predictions with confidence scores"
- "Cat image: 82.8% confidence for 'cat'"
- "Dog image: 99.1% confidence for 'dog'"
- "Model shows excellent performance on both classes"

---

## üé• SCENE 6: Monitoring Dashboard (45 seconds)

**What to Say:**
"Let's check our monitoring dashboards to see the real-time metrics and model performance."

**Actions:**
- Open browser to `http://localhost:3000` (Grafana)
- Show metrics dashboard
- Open browser to `http://localhost:9090` (Prometheus)
- Show metrics data
- Open browser to `http://localhost:5000` (MLflow)
- Show experiment tracking

**Commands to Run:**
```powershell
# Check metrics endpoint
curl http://localhost:8000/metrics

# Run performance monitoring
python model_monitor.py --report
```

**What to Explain:**
- "Grafana provides visual dashboards for model performance"
- "Prometheus collects metrics like request counts and response times"
- "MLflow tracks experiments and model versions"
- "All monitoring is automated and real-time"

---

## üé• SCENE 7: CI/CD Pipeline (30 seconds)

**What to Say:**
"Our GitHub Actions workflow automatically handles the complete CI/CD pipeline. Let me show you what happens when we push changes."

**Actions:**
- Show `.github/workflows/ci-cd.yml` file
- Explain the pipeline stages
- Show GitHub Actions interface (if available)

**What to Explain:**
- "Pipeline stages: Test ‚Üí Build ‚Üí Deploy ‚Üí Monitor"
- "Automated testing ensures code quality"
- "Docker images are built and pushed automatically"
- "Kubernetes deployment is handled by the pipeline"

---

## üé• SCENE 8: Kubernetes Deployment (30 seconds)

**What to Say:**
"For production, we can deploy to Kubernetes using our manifests. Let me show you the deployment configuration."

**Commands to Run:**
```powershell
# Show Kubernetes manifests
cat k8s/deployment.yaml
cat k8s/service.yaml

# Explain key components
```

**What to Explain:**
- "Kubernetes provides scalability and reliability"
- "Deployment manages replicas and rolling updates"
- "Service exposes the API externally"
- "Health checks ensure availability"

---

## üé• SCENE 9: Model Performance & Monitoring (30 seconds)

**What to Say:**
"Let's check our model performance monitoring and drift detection capabilities."

**Commands to Run:**
```powershell
# Run comprehensive monitoring
python model_monitor.py --test-dir data/processed/test --report --check-drift
```

**What to Explain:**
- "Model accuracy is tracked over time"
- "Confidence distributions show prediction quality"
- "Drift detection alerts on performance degradation"
- "All metrics are logged automatically"

---

## üé• SCENE 10: Conclusion (30 seconds)

**What to Say:**
"We've successfully demonstrated a complete MLOps pipeline with automated deployment, monitoring, and CI/CD. The pipeline includes all modern MLOps practices and is production-ready."

**Actions:**
- Show final dashboard with all services running
- Highlight key achievements
- Show project summary

**Key Points to Mention:**
- "Complete MLOps pipeline in under 5 minutes"
- "Automated testing and deployment"
- "Real-time monitoring and alerting"
- "Scalable infrastructure with Kubernetes"
- "Model accuracy: 82.8% for cats, 99.1% for dogs"
- "Production-ready with comprehensive monitoring"

---

## üéØ Video Tips

### üìπ Recording Setup:
- Use 1920x1080 resolution
- Ensure terminal text is readable
- Keep browser windows organized
- Use clear microphone

### ‚è±Ô∏è Timing:
- Total time: 4 minutes 45 seconds
- Each scene: 30-60 seconds
- Smooth transitions between scenes

### üé¨ Presentation Tips:
- Speak clearly and confidently
- Explain technical concepts simply
- Highlight key achievements
- Show actual working commands
- Emphasize automation and reliability

### üîß Technical Notes:
- Have all services running before recording
- Test all commands beforehand
- Keep backup of working state
- Ensure internet connectivity for dashboards

---

## üöÄ Quick Reference Commands

```powershell
# Complete pipeline demo
docker-compose down
docker-compose up -d --build
sleep 30
python smoke_tests.py
curl.exe -X POST -F "file=@Test_img.jpg" http://localhost:8000/predict
curl.exe -X POST -F "file=@Test_img1.jpg" http://localhost:8000/predict
python model_monitor.py --report
```

**Ready to record your amazing MLOps demo! üé•**
